save_every_n_epochs = 10
dataset = "wan_dataset.toml"
output_dir = "./output_wan"
epochs = 10
logging_steps = 10
video_clip_mode = "single_middle"
eval_datasets = []

[general]
train_batch_size = 1
train_on_subset = true
train_subset_size = 1
checkpoint_frequency = 5

[model]
type = "wan"
ckpt_path = "./model_cache/Wan2.1-T2V-1.3B"
dtype = "bfloat16"
timestep_sample_method = "logit_normal"

[optimizer]
type = "adamw"
lr = 0.0005
betas = [ 0.9, 0.999,]
weight_decay = 0.0001
eps = 1e-8

[lr_scheduler]
type = "cosine"
warmup_steps = 100

[adapter]
type = "lora"
rank = 64

[deepspeed]
gradient_accumulation_steps = 1
pipeline_stages = 1
train_micro_batch_size_per_gpu = 1
