epochs = 999999
max_steps = 10
save_every_n_epochs = 999999
checkpoint_every_n_minutes = 1440
dataset = "wan_dataset.toml"
output_dir = "./output_wan"
logging_steps = 10
video_clip_mode = "single_beginning"
pipeline_stages = 2
eval_datasets = []

[general]
train_batch_size = 1
train_on_subset = true
train_subset_size = 1
checkpoint_frequency = 5

[model]
type = "wan"
ckpt_path = "./model_cache/Wan2.1-I2V-14B-480P"
dtype = "bfloat16"
timestep_sample_method = "logit_normal"

[optimizer]
type = "adamw"
lr = 2e-5
betas = [ 0.9, 0.999,]
weight_decay = 0.0001
eps = 1e-8

[lr_scheduler]
type = "cosine"
warmup_steps = 1

[adapter]
type = "lora"
rank = 32

[deepspeed]
gradient_accumulation_steps = 1
pipeline_stages = 2
train_micro_batch_size_per_gpu = 1
